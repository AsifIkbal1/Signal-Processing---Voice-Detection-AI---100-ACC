{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Emirhan BULUT Voice Detection AI Software","metadata":{"id":"eR_MzGi4aO9F"}},{"cell_type":"code","source":"!git clone https://github.com/emirhanai/Audio-Signal-Processing-Artificial-Intelligence-Project.git","metadata":{"execution":{"iopub.status.busy":"2022-10-24T19:31:01.819499Z","iopub.execute_input":"2022-10-24T19:31:01.819928Z","iopub.status.idle":"2022-10-24T19:31:07.69277Z","shell.execute_reply.started":"2022-10-24T19:31:01.819826Z","shell.execute_reply":"2022-10-24T19:31:07.691828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls ./Audio-Signal-Processing-Artificial-Intelligence-Project","metadata":{"execution":{"iopub.status.busy":"2022-10-24T19:31:07.69497Z","iopub.execute_input":"2022-10-24T19:31:07.695446Z","iopub.status.idle":"2022-10-24T19:31:08.806854Z","shell.execute_reply.started":"2022-10-24T19:31:07.695405Z","shell.execute_reply":"2022-10-24T19:31:08.805594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip ./Audio-Signal-Processing-Artificial-Intelligence-Project/data_emir.zip","metadata":{"execution":{"iopub.status.busy":"2022-10-24T19:31:08.808731Z","iopub.execute_input":"2022-10-24T19:31:08.809331Z","iopub.status.idle":"2022-10-24T19:31:10.153871Z","shell.execute_reply.started":"2022-10-24T19:31:08.809284Z","shell.execute_reply":"2022-10-24T19:31:10.152838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport shutil\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom pathlib import Path\nfrom IPython.display import display, Audio\nDATASET_ROOT = os.path.join('./data_load_emir')\nAUDIO_SUBFOLDER = \"datas\"\nNOISE_SUBFOLDER = \"noises\"\nDATASET_AUDIO_PATH = os.path.join(DATASET_ROOT, AUDIO_SUBFOLDER)\nDATASET_NOISE_PATH = os.path.join(DATASET_ROOT, NOISE_SUBFOLDER)\nVALID_SPLIT = 0.1\nSHUFFLE_SEED = 36\nSAMPLING_RATE = 16000\nSCALE = 0.3\nBATCH_SIZE = 128\nEPOCHS = 20","metadata":{"id":"IT_0e4WFMFgN","execution":{"iopub.status.busy":"2022-10-24T19:31:39.571216Z","iopub.execute_input":"2022-10-24T19:31:39.571813Z","iopub.status.idle":"2022-10-24T19:31:39.579132Z","shell.execute_reply.started":"2022-10-24T19:31:39.571778Z","shell.execute_reply":"2022-10-24T19:31:39.57799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if os.path.exists(DATASET_AUDIO_PATH) is False:\n    os.makedirs(DATASET_AUDIO_PATH)\nif os.path.exists(DATASET_NOISE_PATH) is False:\n    os.makedirs(DATASET_NOISE_PATH)\nfor folder in os.listdir(DATASET_ROOT):\n    if os.path.isdir(os.path.join(DATASET_ROOT, folder)):\n        if folder in [AUDIO_SUBFOLDER, NOISE_SUBFOLDER]:\n            continue\n        elif folder in [\"other\", \"_background_noise_\"]:\n            shutil.move(\n                os.path.join(DATASET_ROOT, folder),\n                os.path.join(DATASET_NOISE_PATH, folder),\n            )\n        else:\n            shutil.move(\n                os.path.join(DATASET_ROOT, folder),\n                os.path.join(DATASET_AUDIO_PATH, folder),\n            )","metadata":{"id":"m0x0ObDfMFgQ","execution":{"iopub.status.busy":"2022-10-24T19:33:05.012144Z","iopub.execute_input":"2022-10-24T19:33:05.013266Z","iopub.status.idle":"2022-10-24T19:33:05.023366Z","shell.execute_reply.started":"2022-10-24T19:33:05.013212Z","shell.execute_reply":"2022-10-24T19:33:05.022373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"noise_paths = []\nfor subdir in os.listdir(DATASET_NOISE_PATH):\n    subdir_path = Path(DATASET_NOISE_PATH) / subdir\n    if os.path.isdir(subdir_path):\n        noise_paths += [\n            os.path.join(subdir_path, filepath)\n            for filepath in os.listdir(subdir_path)\n            if filepath.endswith(\".wav\")\n        ]\n\nprint(\n    \"{} files found in {} directories\".format(\n        len(noise_paths), len(os.listdir(DATASET_NOISE_PATH))\n    )\n)","metadata":{"id":"DiMq8CV4MFgS","outputId":"91211f90-b750-4939-f233-4b7694065370","execution":{"iopub.status.busy":"2022-10-24T19:33:15.303689Z","iopub.execute_input":"2022-10-24T19:33:15.304139Z","iopub.status.idle":"2022-10-24T19:33:15.31122Z","shell.execute_reply.started":"2022-10-24T19:33:15.304107Z","shell.execute_reply":"2022-10-24T19:33:15.310197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Resample all noise samples to 16000 Hz","metadata":{"id":"HXMaPkbmMFgT"}},{"cell_type":"code","source":"command = (\n    \"for dir in `ls -1 \" + DATASET_NOISE_PATH + \"`; do \"\n    \"for file in `ls -1 \" + DATASET_NOISE_PATH + \"/$dir/*.wav`; do \"\n    \"sample_rate=`ffprobe -hide_banner -loglevel panic -show_streams \"\n    \"$file | grep sample_rate | cut -f2 -d=`; \"\n    \"if [ $sample_rate -ne 16000 ]; then \"\n    \"ffmpeg -hide_banner -loglevel panic -y \"\n    \"-i $file -ar 16000 temp.wav; \"\n    \"mv temp.wav $file; \"\n    \"fi; done; done\"\n)\nos.system(command)\n\ndef load_noise_sample(path):\n    sample, sampling_rate = tf.audio.decode_wav(\n        tf.io.read_file(path), desired_channels=1\n    )\n    if sampling_rate == SAMPLING_RATE:\n        slices = int(sample.shape[0] / SAMPLING_RATE)\n        sample = tf.split(sample[: slices * SAMPLING_RATE], slices)\n        return sample\n    else:\n        print(\"Sampling rate for {} is incorrect. Ignoring it\".format(path))\n        return None\n\n\nnoises = []\nfor path in noise_paths:\n    sample = load_noise_sample(path)\n    if sample:\n        noises.extend(sample)\nnoises = tf.stack(noises)\n\nprint(\n    \"{} noise files were split into {} noise samples where each is {} sec. long\".format(\n        len(noise_paths), noises.shape[0], noises.shape[1] // SAMPLING_RATE\n    )\n)","metadata":{"id":"yVysMM7OMFgU","outputId":"94e5cae3-5d26-4be4-c2d4-753c5fef033f","execution":{"iopub.status.busy":"2022-10-24T19:33:15.317277Z","iopub.execute_input":"2022-10-24T19:33:15.317584Z","iopub.status.idle":"2022-10-24T19:33:15.855947Z","shell.execute_reply.started":"2022-10-24T19:33:15.317555Z","shell.execute_reply":"2022-10-24T19:33:15.854611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def paths_and_labels_to_dataset(audio_paths, labels):\n    path_ds = tf.data.Dataset.from_tensor_slices(audio_paths)\n    audio_ds = path_ds.map(lambda x: path_to_audio(x))\n    label_ds = tf.data.Dataset.from_tensor_slices(labels)\n    return tf.data.Dataset.zip((audio_ds, label_ds))\n\n\ndef path_to_audio(path):\n    audio = tf.io.read_file(path)\n    audio, _ = tf.audio.decode_wav(audio, 1, SAMPLING_RATE)\n    return audio\n\n\ndef add_noise(audio, noises=None, scale=0.5):\n    if noises is not None:\n        tf_rnd = tf.random.uniform(\n            (tf.shape(audio)[0],), 0, noises.shape[0], dtype=tf.int32\n        )\n        noise = tf.gather(noises, tf_rnd, axis=0)\n        prop = tf.math.reduce_max(audio, axis=1) / tf.math.reduce_max(noise, axis=1)\n        prop = tf.repeat(tf.expand_dims(prop, axis=1), tf.shape(audio)[1], axis=1)\n        audio = audio + noise * prop * scale\n\n    return audio\n\n\ndef audio_to_fft(audio):\n    audio = tf.squeeze(audio, axis=-1)\n    fft = tf.signal.fft(\n        tf.cast(tf.complex(real=audio, imag=tf.zeros_like(audio)), tf.complex64)\n    )\n    fft = tf.expand_dims(fft, axis=-1)\n    return tf.math.abs(fft[:, : (audio.shape[1] // 2), :])\nclass_names = os.listdir(DATASET_AUDIO_PATH)\nprint(\"Our class names: {}\".format(class_names,))\n\naudio_paths = []\nlabels = []\nfor label, name in enumerate(class_names):\n    print(\"Processing voices {}\".format(name,))\n    dir_path = Path(DATASET_AUDIO_PATH) / name\n    voice_sample_paths = [\n        os.path.join(dir_path, filepath)\n        for filepath in os.listdir(dir_path)\n        if filepath.endswith(\".wav\")\n    ]\n    audio_paths += voice_sample_paths\n    labels += [label] * len(voice_sample_paths)\n\nprint(\n    \"Found {} files belonging to {} classes.\".format(len(audio_paths), len(class_names))\n)\n\nrng = np.random.RandomState(SHUFFLE_SEED)\nrng.shuffle(audio_paths)\nrng = np.random.RandomState(SHUFFLE_SEED)\nrng.shuffle(labels)\n\nnum_val_samples = int(VALID_SPLIT * len(audio_paths))\nprint(\"Using {} files for training.\".format(len(audio_paths) - num_val_samples))\ntrain_audio_paths = audio_paths[:-num_val_samples]\ntrain_labels = labels[:-num_val_samples]\n\nprint(\"Using {} files for validation.\".format(num_val_samples))\nvalid_audio_paths = audio_paths[-num_val_samples:]\nvalid_labels = labels[-num_val_samples:]\n\ntrain_ds = paths_and_labels_to_dataset(train_audio_paths, train_labels)\ntrain_ds = train_ds.shuffle(buffer_size=BATCH_SIZE * 8, seed=SHUFFLE_SEED).batch(\n    BATCH_SIZE\n)\n\nvalid_ds = paths_and_labels_to_dataset(valid_audio_paths, valid_labels)\nvalid_ds = valid_ds.shuffle(buffer_size=32 * 8, seed=SHUFFLE_SEED).batch(32)\n\ntrain_ds = train_ds.map(\n    lambda x, y: (add_noise(x, noises, scale=SCALE), y),\n    num_parallel_calls=tf.data.AUTOTUNE,\n)\n\ntrain_ds = train_ds.map(\n    lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.AUTOTUNE\n)\ntrain_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n\nvalid_ds = valid_ds.map(\n    lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.AUTOTUNE\n)\nvalid_ds = valid_ds.prefetch(tf.data.AUTOTUNE)","metadata":{"id":"IdJEFICrMFgV","outputId":"644a8728-516c-47e2-a999-99a4a055e369","execution":{"iopub.status.busy":"2022-10-24T19:33:15.858824Z","iopub.execute_input":"2022-10-24T19:33:15.859199Z","iopub.status.idle":"2022-10-24T19:33:16.399254Z","shell.execute_reply.started":"2022-10-24T19:33:15.859152Z","shell.execute_reply":"2022-10-24T19:33:16.398448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model(input_shape, num_classes):\n    inputs = keras.layers.Input(shape=input_shape, name=\"input_name\")\n\n    x = keras.layers.Conv1D(16, 2)(inputs)\n    x = keras.layers.MaxPool1D(pool_size=2, strides=2)(x)\n    x = keras.layers.Flatten()(x)\n    x = keras.layers.Dense(32, activation=\"relu\")(x)\n    x = keras.layers.Dense(64, activation=\"relu\")(x)\n\n    outputs = keras.layers.Dense(num_classes, activation=\"sigmoid\", name=\"output\")(x)\n\n    return keras.models.Model(inputs=inputs, outputs=outputs)\n\n\nmodel = build_model((SAMPLING_RATE // 2, 1), len(class_names))\n\nmodel.summary()\n\nmodel.compile(\n    optimizer=\"Adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n)\n\nmodel_save_filename = \"model_emir.h5\"\n\nearlystopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\nmdlcheckpoint_cb = keras.callbacks.ModelCheckpoint(\n    model_save_filename, monitor=\"val_accuracy\", save_best_only=True\n)","metadata":{"id":"2bL9yYGzMFgW","outputId":"b89d3822-ed25-4f46-9855-e35fc5f59372","execution":{"iopub.status.busy":"2022-10-24T19:33:36.578142Z","iopub.execute_input":"2022-10-24T19:33:36.578654Z","iopub.status.idle":"2022-10-24T19:33:36.682414Z","shell.execute_reply.started":"2022-10-24T19:33:36.578598Z","shell.execute_reply":"2022-10-24T19:33:36.681431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    train_ds,\n    epochs=EPOCHS,\n    validation_data=valid_ds,\n    callbacks=[earlystopping_cb, mdlcheckpoint_cb],\n)","metadata":{"id":"JH_ipsSgMFgX","outputId":"048fce11-871c-42ed-9bf3-3698d816c1ca","execution":{"iopub.status.busy":"2022-10-24T19:33:36.684451Z","iopub.execute_input":"2022-10-24T19:33:36.685416Z","iopub.status.idle":"2022-10-24T19:33:46.375302Z","shell.execute_reply.started":"2022-10-24T19:33:36.68537Z","shell.execute_reply":"2022-10-24T19:33:46.374205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(model.evaluate(valid_ds))","metadata":{"id":"4Ut4g369MFgX","outputId":"86b1c2e6-2181-4b8f-8fed-90a85245bc1c","execution":{"iopub.status.busy":"2022-10-24T19:33:46.377073Z","iopub.execute_input":"2022-10-24T19:33:46.377422Z","iopub.status.idle":"2022-10-24T19:33:46.453455Z","shell.execute_reply.started":"2022-10-24T19:33:46.377388Z","shell.execute_reply":"2022-10-24T19:33:46.452431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_example = 1\n\ntest_ds = paths_and_labels_to_dataset(valid_audio_paths, valid_labels)\ntest_ds = test_ds.shuffle(buffer_size=BATCH_SIZE * 8, seed=SHUFFLE_SEED).batch(\n    BATCH_SIZE\n)\n\ntest_ds = test_ds.map(lambda x, y: (add_noise(x, noises, scale=SCALE), y))\n\nfor audios, labels in test_ds.take(1):\n    ffts = audio_to_fft(audios)\n    y_pred = model.predict(ffts)\n    rnd = np.random.randint(0, 1, display_example)\n    audios = audios.numpy()[rnd, :, :]\n    labels = labels.numpy()[rnd]\n    y_pred = np.argmax(y_pred, axis=-1)[rnd]\n\n    for index in range(display_example):\n        print(\n            \"Voice Type:\\33{} {}\\33[0m\\tPredicted:\\33{} {}\\33[0m\".format(\n                \"[92m\" if labels[index] == y_pred[index] else \"[91m\",\n                class_names[labels[index]],\n                \"[92m\" if labels[index] == y_pred[index] else \"[91m\",\n                class_names[y_pred[index]],\n            )\n        )\n        display(Audio(audios[index, :, :].squeeze(), rate=SAMPLING_RATE))","metadata":{"id":"fsam7gNTMFgY","outputId":"792ef124-c435-48d4-e66b-18e2283b890a","execution":{"iopub.status.busy":"2022-10-24T19:33:46.455593Z","iopub.execute_input":"2022-10-24T19:33:46.455827Z","iopub.status.idle":"2022-10-24T19:33:46.761021Z","shell.execute_reply.started":"2022-10-24T19:33:46.455801Z","shell.execute_reply":"2022-10-24T19:33:46.760274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip model_emir.zip model_emir.h5","metadata":{"id":"2bQ5ihnAbLIF","outputId":"124aab71-4094-46c0-d8c2-a427257ee161","execution":{"iopub.status.busy":"2022-10-24T19:34:05.592098Z","iopub.execute_input":"2022-10-24T19:34:05.592466Z","iopub.status.idle":"2022-10-24T19:34:08.219853Z","shell.execute_reply.started":"2022-10-24T19:34:05.592426Z","shell.execute_reply":"2022-10-24T19:34:08.218434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls ./","metadata":{"execution":{"iopub.status.busy":"2022-10-24T19:34:24.139646Z","iopub.execute_input":"2022-10-24T19:34:24.140006Z","iopub.status.idle":"2022-10-24T19:34:25.269371Z","shell.execute_reply.started":"2022-10-24T19:34:24.139965Z","shell.execute_reply":"2022-10-24T19:34:25.268244Z"},"trusted":true},"execution_count":null,"outputs":[]}]}